---
title: "Model Comparison"
output: html_document
---

```{r}
#! echo=FALSE

PROJECT_PATH <- "~/BayesianRecordLinkage/"

suppressPackageStartupMessages(library(RecordLinkage))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(gtools))
suppressPackageStartupMessages(library(mvtnorm))
suppressPackageStartupMessages(library(pracma))
suppressPackageStartupMessages(library(coda))
suppressPackageStartupMessages(library(testit))
suppressPackageStartupMessages(library(VaRES))
suppressPackageStartupMessages(library(parallel))
suppressPackageStartupMessages(library(Rcpp))
suppressPackageStartupMessages(library(BRL))
suppressPackageStartupMessages(library(viridis))
suppressPackageStartupMessages(library(fields))
suppressPackageStartupMessages(library(pbapply))

purrr::walk(
  list.files(
    paste0(PROJECT_PATH, "helper_fns/helper_fns_R"),
    pattern = "*.R$",
    full.names = TRUE
  ),
  source,
  .GlobalEnv
)

set.seed(1231)
MCMC_end_index <- 1000
```

# Best Scenario

$R^2 = 0.9$, $overlap=0.5$, $n\_error=3$

## Train data

```{r best}
dataset <- 0
n_error <- 3
overlap_proportion <- 0.5
R_sq <- 0.9
seed_proportion <- 0.05

# load data
records <- read.csv(
  paste(
    PROJECT_PATH,
    "Simulation Datafiles/",
    "percdups50_nerrors",
    n_error,
    "_dataset",
    dataset,
    "_4fields_twofiles_BRLpaper.csv",
    sep = ""
  )
)
records$file <- rep(2:1, length.out = dim(records)[1])
records <- records[records$file %in% c(1, 2), ] # pick original record and first dup

# Preprocess data (create 5 sub-datasets) -----------------------------
preprocessed_data_best <- PreProcess_SimulationData_withSeed(
  records = records,
  num_simu = 1,
  n1 = 500,
  n2 = 500,
  overlap_proportion = overlap_proportion,
  R_sq = R_sq,
  seed_proportion = seed_proportion
)

file_1_best <- preprocessed_data_best[[1]]$file_1
file_2_best <- preprocessed_data_best[[1]]$file_2
gamma_best <- preprocessed_data_best[[1]]$gamma
Z_known <- preprocessed_data_best[[1]]$Z_known

# Run MCMC with Sadinle's code (in C language) ------------------------
gamma_in_c <- compareRecords(file_1_best, file_2_best, flds=c("gname", "fname", "age", "occup"), types=c("lv","lv","bi","bi"), breaks=c(0,.25,.5))
mcmc <- bipartiteGibbs(gamma_in_c, nIter=1000, a=1, b=1, aBM=1, bBM=1, seed=1231)
Z_best = t(mcmc$Z)
m_best <- lapply(1:1000, function(s) {res <- list(f1 = mcmc$m[1:4,s], f2 = mcmc$m[5:8,s], f3 = mcmc$m[9:10,s], f4 = mcmc$m[11:12,s])})
u_best <- lapply(1:1000, function(s) {res <- list(f1 = mcmc$u[1:4,s], f2 = mcmc$u[5:8,s], f3 = mcmc$u[9:10,s], f4 = mcmc$u[11:12,s])})

# estimate p.y
mu.y <- mean(file_2_best$y)
sigma.y <- sqrt(sum((file_2_best$y-mu.y)^2)/nrow(file_2_best))

EM_and_TSols_history_best <- pblapply(
  101:MCMC_end_index, # first 100 iters of MCMC are burn-in
  function(s){
    # run loop to calculate and save EM result
    Z_tmp <- Z_best[s,]
    m_tmp <- m_best[[s]]
    u_tmp <- u_best[[s]]
    linked_data_tmp <- z2regdata_with_goodness(Z_tmp, file_1_best, file_2_best, m_tmp, u_tmp, gamma_best)
    X_tmp = linked_data_tmp$X
    Y_tmp = linked_data_tmp$Y
    G_tmp = linked_data_tmp$G
    BCIIL_result <- EM_estimation_with_process(
      X = X_tmp,
      Y = Y_tmp,
      G = G_tmp,
      p.y = function(y){dnorm(y, mean = mu.y, sd = sigma.y)}
    )
    
    linked_data_tmp <- z2regdata_withSeed(Z_tmp, file_1_best, file_2_best, Z_known)
    Seed.vec_tmp <- linked_data_tmp$Seed.vec
    BNCIL_result <- EM_estimation_withSeed_process(
      X = as.numeric(X_tmp[,2]),
      Y = as.numeric(Y_tmp),
      Seed.vec = as.numeric(Seed.vec_tmp),
      p.y = function(y){dnorm(y, mean = mu.y, sd = sigma.y)}
    )
    # run loop to calculate and save TS.OLS result
    TS.OLS_coefficients <- solve(t(X_tmp) %*% X_tmp) %*% t(X_tmp) %*% Y_tmp
    TS.OLS_cov <- sum((Y_tmp - X_tmp %*% TS.OLS_coefficients)^2)/(nrow(X_tmp)-ncol(X_tmp)) * solve(t(X_tmp) %*% X_tmp)
    
    results <- list(
      BCIIL_result = BCIIL_result,
      BNCIL_result = BNCIL_result,
      TS.OLS_coefficients = TS.OLS_coefficients,
      TS.OLS_cov = TS.OLS_cov,
      Z = Z_tmp,
      G = G_tmp
    )
    return(results)
  }
)
```

```{r}
threshold <- 0.5

# Create ground truth Z as benchmark
Z_groundtruth <- rep(0, 500)
for (i in 1:500) {
  id.2 <- file_2_best$rec.id[i]
  if (id.2 %in% file_1_best$rec.id) {
    Z_groundtruth[i] <- which(id.2 == file_1_best$rec.id)
  } else {
    Z_groundtruth[i] <- i + 500
  }
}

confusion.EM_and_TSOLS <- map_df(1:length(EM_and_TSols_history_best), function(i) {
  # ----------------- TS.OLS -------------------
  Z_TSOLS <- EM_and_TSols_history_best[[i]][["Z"]]
  
  accuracy.TSOLS <- sum(Z_TSOLS<=500 & Z_TSOLS == Z_groundtruth, na.rm = TRUE)/sum(Z_TSOLS <= 500)

  # ----------------- PLMIc -------------------
  Z_BCIIL <- EM_and_TSols_history_best[[i]][["Z"]]
  prob_history <- EM_and_TSols_history_best[[i]]$BCIIL_result$prob_history
  last_col <- dim(prob_history)[2]
  latent_class_probs <- prob_history[, last_col]
  remove_link <- latent_class_probs < threshold
  link_indices <- which(Z_BCIIL <= 500)
  Z_BCIIL[link_indices[remove_link]] <- 1000
  
  accuracy.BCIIL <- sum(Z_BCIIL<=500 & Z_BCIIL == Z_groundtruth, na.rm = TRUE)/sum(Z_BCIIL <= 500)

  # ----------------- PLMI -------------------
  Z_BNCIL <- EM_and_TSols_history_best[[i]][["Z"]]
  remove_link <- EM_and_TSols_history_best[[i]]$BNCIL_result$param_prob < threshold
  link_indices <- which(Z_BNCIL <= 500)
  Z_BNCIL[link_indices[remove_link]] <- 1000

  accuracy.BNCIL <-sum(Z_BNCIL<=500 & Z_BNCIL == Z_groundtruth, na.rm = TRUE)/sum(Z_BNCIL <= 500)

  # Return results
  tibble(
    accuracy.BCIIL = accuracy.BCIIL,
    accuracy.TSOLS = accuracy.TSOLS,
    accuracy.BNCIL = accuracy.BNCIL
  )
})
```

```{r}
# Set up the plot
plot(
  1:(MCMC_end_index - 100),
  confusion.EM_and_TSOLS$accuracy.BCIIL,
  type = "l",
  col = "blue",
  lwd = 2,
  ylim = c(0.75, 1),
  xlab = "MCMC Iteration",
  ylab = "Accuracy",
  cex.lab = 1.2,
  cex.main = 1.3
)

# Add PLMI accuracy line
lines(
  1:(MCMC_end_index - 100),
  confusion.EM_and_TSOLS$accuracy.BNCIL,
  col = "darkgreen",
  lwd = 2,
  lty = 1
)

# Add TS.OLS accuracy line
lines(
  1:(MCMC_end_index - 100),
  confusion.EM_and_TSOLS$accuracy.TSOLS,
  col = "red",
  lwd = 2,
  lty = 1
)

# Add legend
legend(
  "bottomright",
  legend = c("PLMIc (no seeds)", "PLMI (5% seeds)", "TS.OLS"),
  col = c("blue","darkgreen", "red"),
  lwd = 2,
  lty = c(1, 1, 1),
  bty = "n"
)

```

```{r}
id <- 229
prob_mat <- EM_and_TSols_history_best[[id]]$BCIIL_result$prob_history
prob_mat <- cbind(rep(0.5, nrow(prob_mat)), prob_mat)

Z_tmp <- EM_and_TSols_history_best[[id]]$Z
id_1 <- file_1_best$rec.id; id_2 <- file_2_best$rec.id
Z_true <- 1:500 + 500
for (i in 1:500) {
  if (id_2[i] %in% id_1) {
    Z_true[i] <- match(id_2[i], id_1)
  }
}

Z_true <- Z_true[Z_tmp <= 500]
Z_tmp <- Z_tmp[Z_tmp <= 500]

link_status <- Z_tmp == Z_true

rows_true <- prob_mat[link_status, ]
rows_false <- prob_mat[!link_status, ]

# set plot space
plot(
  x = 1:ncol(prob_mat),
  y = rows_true[1, ],
  type = 'l',
  ylim = c(0, 1),
  xlab = "EM Iteration",
  ylab = "Probability",
  col = rgb(0, 0, 1, 0.3)  # transparency 0.3
)

# add row of true link (blue)
if (nrow(rows_true) > 1) {
  for (i in 2:nrow(rows_true)) {
    lines(1:ncol(prob_mat), rows_true[i, ], col = rgb(0, 0, 1, 0.2))
  }
}

# add all rows of false link (red)
for (i in 1:nrow(rows_false)) {
  lines(1:ncol(prob_mat), rows_false[i, ], col = rgb(1, 0, 0, 0.4))
}

abline(h = 0.5, col = "black", lty = 2) # add horizontal line at 0.5
# add text 0.5
text(
  x = ncol(prob_mat) - 0.5,
  y = 0.55,
  labels = "0.5",
  col = "black",
  cex = 1.2
)
# legend
legend(
  "bottomright",
  legend = c("True Links", "False Links"),
  col = c("blue", "red"),
  lwd = 2,
  bty = "n"
)
```


# Worst scenario

```{r best}
dataset <- 0
n_error <- 1
overlap_proportion <- 0.5
R_sq <- 0.6
seed_proportion <- 0.05

# load data
records <- read.csv(
  paste(
    PROJECT_PATH,
    "ConfInterv_Evaluation_DCC/Simulation Datafiles/",
    "percdups50_nerrors",
    n_error,
    "_dataset",
    dataset,
    "_4fields_twofiles_BRLpaper.csv",
    sep = ""
  )
)
records$file <- rep(2:1, length.out = dim(records)[1])
records <- records[records$file %in% c(1, 2), ] # pick original record and first dup

# Preprocess data (create 5 sub-datasets) -----------------------------
preprocessed_data_best <- PreProcess_SimulationData_withSeed(
  records = records,
  num_simu = 1,
  n1 = 500,
  n2 = 500,
  overlap_proportion = overlap_proportion,
  R_sq = R_sq,
  seed_proportion = seed_proportion
)

file_1_best <- preprocessed_data_best[[1]]$file_1
file_2_best <- preprocessed_data_best[[1]]$file_2
gamma_best <- preprocessed_data_best[[1]]$gamma
Z_known <- preprocessed_data_best[[1]]$Z_known

# Run MCMC with Sadinle's code (in C language) ------------------------
gamma_in_c <- compareRecords(file_1_best, file_2_best, flds=c("gname", "fname", "age", "occup"), types=c("lv","lv","bi","bi"), breaks=c(0,.25,.5))
mcmc <- bipartiteGibbs(gamma_in_c, nIter=1000, a=1, b=1, aBM=1, bBM=1, seed=1231)
Z_best = t(mcmc$Z)
m_best <- lapply(1:1000, function(s) {res <- list(f1 = mcmc$m[1:4,s], f2 = mcmc$m[5:8,s], f3 = mcmc$m[9:10,s], f4 = mcmc$m[11:12,s])})
u_best <- lapply(1:1000, function(s) {res <- list(f1 = mcmc$u[1:4,s], f2 = mcmc$u[5:8,s], f3 = mcmc$u[9:10,s], f4 = mcmc$u[11:12,s])})

# estimate p.y
mu.y <- mean(file_2_best$y)
sigma.y <- sqrt(sum((file_2_best$y-mu.y)^2)/nrow(file_2_best))

EM_and_TSols_history_best <- pblapply(
  101:MCMC_end_index, # first 100 iters of MCMC are burn-in
  function(s){
    # run loop to calculate and save EM result
    Z_tmp <- Z_best[s,]
    m_tmp <- m_best[[s]]
    u_tmp <- u_best[[s]]
    linked_data_tmp <- z2regdata_with_goodness(Z_tmp, file_1_best, file_2_best, m_tmp, u_tmp, gamma_best)
    X_tmp = linked_data_tmp$X
    Y_tmp = linked_data_tmp$Y
    G_tmp = linked_data_tmp$G
    BCIIL_result <- EM_estimation_with_process(
      X = X_tmp,
      Y = Y_tmp,
      G = G_tmp,
      p.y = function(y){dnorm(y, mean = mu.y, sd = sigma.y)}
    )
    
    linked_data_tmp <- z2regdata_withSeed(Z_tmp, file_1_best, file_2_best, Z_known)
    Seed.vec_tmp <- linked_data_tmp$Seed.vec
    BNCIL_result <- EM_estimation_withSeed_process(
      X = as.numeric(X_tmp[,2]),
      Y = as.numeric(Y_tmp),
      Seed.vec = as.numeric(Seed.vec_tmp),
      p.y = function(y){dnorm(y, mean = mu.y, sd = sigma.y)}
    )
    # run loop to calculate and save TS.OLS result
    TS.OLS_coefficients <- solve(t(X_tmp) %*% X_tmp) %*% t(X_tmp) %*% Y_tmp
    TS.OLS_cov <- sum((Y_tmp - X_tmp %*% TS.OLS_coefficients)^2)/(nrow(X_tmp)-ncol(X_tmp)) * solve(t(X_tmp) %*% X_tmp)
    
    results <- list(
      BCIIL_result = BCIIL_result,
      BNCIL_result = BNCIL_result,
      TS.OLS_coefficients = TS.OLS_coefficients,
      TS.OLS_cov = TS.OLS_cov,
      Z = Z_tmp,
      G = G_tmp
    )
    return(results)
  }
)
```

```{r}
threshold <- 0.5

# Create ground truth Z as benchmark
Z_groundtruth <- rep(0, 500)
for (i in 1:500) {
  id.2 <- file_2_best$rec.id[i]
  if (id.2 %in% file_1_best$rec.id) {
    Z_groundtruth[i] <- which(id.2 == file_1_best$rec.id)
  } else {
    Z_groundtruth[i] <- i + 500
  }
}

confusion.EM_and_TSOLS <- map_df(1:length(EM_and_TSols_history_best), function(i) {
  # ----------------- TS.OLS -------------------
  Z_TSOLS <- EM_and_TSols_history_best[[i]][["Z"]]
  
  accuracy.TSOLS <- sum(Z_TSOLS<=500 & Z_TSOLS == Z_groundtruth, na.rm = TRUE)/sum(Z_TSOLS <= 500)

  # ----------------- BCIIL -------------------
  Z_BCIIL <- EM_and_TSols_history_best[[i]][["Z"]]
  prob_history <- EM_and_TSols_history_best[[i]]$BCIIL_result$prob_history
  last_col <- dim(prob_history)[2]
  latent_class_probs <- prob_history[, last_col]
  remove_link <- latent_class_probs < threshold
  link_indices <- which(Z_BCIIL <= 500)
  Z_BCIIL[link_indices[remove_link]] <- 1000
  
  accuracy.BCIIL <- sum(Z_BCIIL<=500 & Z_BCIIL == Z_groundtruth, na.rm = TRUE)/sum(Z_BCIIL <= 500)

  # ----------------- BNCIL -------------------
  Z_BNCIL <- EM_and_TSols_history_best[[i]][["Z"]]
  remove_link <- EM_and_TSols_history_best[[i]]$BNCIL_result$param_prob < threshold
  link_indices <- which(Z_BNCIL <= 500)
  Z_BNCIL[link_indices[remove_link]] <- 1000

  accuracy.BNCIL <-sum(Z_BNCIL<=500 & Z_BNCIL == Z_groundtruth, na.rm = TRUE)/sum(Z_BNCIL <= 500)

  # Return results
  tibble(
    accuracy.BCIIL = accuracy.BCIIL,
    accuracy.TSOLS = accuracy.TSOLS,
    accuracy.BNCIL = accuracy.BNCIL
  )
})
```

```{r}
# Set up the plot
plot(
  1:(MCMC_end_index - 100),
  confusion.EM_and_TSOLS$accuracy.BCIIL,
  type = "l",
  col = "blue",
  lwd = 2,
  ylim = c(0.75, 1),
  xlab = "MCMC Iteration",
  ylab = "Accuracy",
  cex.lab = 1.2,
  cex.main = 1.3
)

# Add BNCIL accuracy line
lines(
  1:(MCMC_end_index - 100),
  confusion.EM_and_TSOLS$accuracy.BNCIL,
  col = "darkgreen",
  lwd = 2,
  lty = 2
)

# Add TS.OLS accuracy line
lines(
  1:(MCMC_end_index - 100),
  confusion.EM_and_TSOLS$accuracy.TSOLS,
  col = "red",
  lwd = 2,
  lty = 3
)

# Add legend
legend(
  "bottomright",
  legend = c("BCIIL (no seeds)", "BNCIL (5% seeds)", "TS.OLS"),
  col = c("blue", "darkgreen", "red"),
  lwd = 2,
  lty = c(1, 2, 3),
  bty = "n"
)
```

```{r}
id <- 229
prob_mat <- EM_and_TSols_history_best[[id]]$BCIIL_result$prob_history
prob_mat <- cbind(rep(0.5, nrow(prob_mat)), prob_mat)

Z_tmp <- EM_and_TSols_history_best[[id]]$Z
id_1 <- file_1_best$rec.id; id_2 <- file_2_best$rec.id
Z_true <- 1:500 + 500
for (i in 1:500) {
  if (id_2[i] %in% id_1) {
    Z_true[i] <- match(id_2[i], id_1)
  }
}

Z_true <- Z_true[Z_tmp <= 500]
Z_tmp <- Z_tmp[Z_tmp <= 500]

link_status <- Z_tmp == Z_true

rows_true <- prob_mat[link_status, ]
rows_false <- prob_mat[!link_status, ]

# set plot space
plot(
  x = 1:ncol(prob_mat),
  y = rows_true[1, ],
  type = 'l',
  ylim = c(0, 1),
  xlab = "EM Iteration",
  ylab = "probability",
  col = rgb(0, 0, 1, 0.3)  # transparency 0.3
)

# add row of true link (blue)
if (nrow(rows_true) > 1) {
  for (i in 2:nrow(rows_true)) {
    lines(1:ncol(prob_mat), rows_true[i, ], col = rgb(0, 0, 1, 0.2))
  }
}

# add all rows of false link (red)
for (i in 1:nrow(rows_false)) {
  lines(1:ncol(prob_mat), rows_false[i, ], col = rgb(1, 0, 0, 0.4))
}

abline(h = 0.5, col = "black", lty = 2) # add horizontal line at 0.5
# add text 0.5
text(
  x = ncol(prob_mat) - 0.5,
  y = 0.55,
  labels = "0.5",
  col = "black",
  cex = 1.2
)
# legend
legend(
  "bottomright",
  legend = c("True Links", "False Links"),
  col = c("blue", "red"),
  lwd = 2,
  bty = "n"
)
```




